role: Agent

env:
  - name: OPENOBSERVE_AUTH_B64
    valueFrom:
      secretKeyRef:
        name: openobserve-auth-creds
        key: auth_b64
  - name: EXCLUDED_NAMESPACES
    value: otel-collector,vector,default,kube-node-lease,kube-public
  - name: ERROR_FILTERED_NAMESPACES
    value: kube-system,cert-manager,openobserve,cnpg-system,grafana,rabbitmq-system,tempo,victoria-metrics,mongodb,redis,rabbitmq,external-dns
  - name: ROUTED_NAMESPACES
    value: kube-system,cert-manager,openobserve,cnpg-system,grafana,rabbitmq-system,tempo,victoria-metrics,mongodb,redis,rabbitmq,external-dns
  - name: PROJECT
    valueFrom:
      configMapKeyRef:
        name: cluster-labels
        key: project
  - name: APP
    valueFrom:
      configMapKeyRef:
        name: cluster-labels
        key: app
  - name: REGION
    valueFrom:
      configMapKeyRef:
        name: cluster-labels
        key: region
  - name: CLUSTER_ID
    valueFrom:
      configMapKeyRef:
        name: cluster-labels
        key: cluster_id
  - name: ENV
    valueFrom:
      configMapKeyRef:
        name: cluster-labels
        key: env

service:
  enabled: false

resources:
  requests:
    cpu: 25m
    memory: 256Mi
  limits:
    cpu: 100m
    memory: 384Mi

customConfig:
  data_dir: /vector-data-dir

  # -----------------------------------------------------------------------
  # 1. SOURCES
  # -----------------------------------------------------------------------
  sources:
    kubernetes_logs:
      type: kubernetes_logs
    
    system_logs:
      type: file
      include: [/var/log/*log]

  # -----------------------------------------------------------------------
  # 1. SOURCES
  # -----------------------------------------------------------------------
  sources:
    kubernetes_logs:
      type: kubernetes_logs
    
    system_logs:
      type: file
      include: [/var/log/*log]

  # -----------------------------------------------------------------------
  # 2. TRANSFORMS
  # -----------------------------------------------------------------------
  transforms:
    # Step 1: Parse JSON or extract log levels from messages
    unified_parser:
      type: remap
      inputs: [kubernetes_logs, system_logs]
      source: |
        # Attempt to parse JSON
        parsed, err = parse_json(.message)
        if err == null && is_object(parsed) {
          ., _ = merge(., parsed)
          
          # Handle MongoDB JSON format mapping
          # Only apply if we haven't found a standard 'level' field yet
          if .level == null {
            if .s == "I" { .level = "INFO" }
            if .s == "W" { .level = "WARNING" }
            if .s == "E" { .level = "ERROR" }
            if .s == "F" { .level = "FATAL" }
            if .s == "D" { .level = "DEBUG" }
          }
        }
        
        # If not JSON, try to parse plain text logs
        if is_string(.message) {
          # 1. Strip ANSI color codes (fixes MongoDB/Bitnami logs and makes logs readable)
          .message = strip_ansi_escape_codes(.message) ?? .message
          
          # 3. Pattern Matching
          
          # Pattern 1: "INFO: message"
          if .level == null { 
            match, err = parse_regex(.message, r'^(?P<level>(DBG|DEBUG|INF|INFO|WARN|WARNING|ERROR|CRITICAL|FATAL)):\s.*')
            if err == null { .level = match.level }
          }

          # Pattern 2: "timestamp LEVEL message"
          if .level == null {
            match, err = parse_regex(.message, r'^\S+\s+(?P<level>(DBG|DEBUG|INF|INFO|WARN|WARNING|ERROR|CRITICAL|FATAL))\s.*')
            if err == null { .level = match.level }
          }

          # Pattern 3: "[INFO] message"
          if .level == null {
            match, err = parse_regex(.message, r'^\[(?P<level>(DBG|DEBUG|INF|INFO|WARN|WARNING|ERROR|CRITICAL|FATAL))\]\s.*')
            if err == null { .level = match.level }
          }

          # Pattern 4: Bitnami/MongoDB "app time LEVEL ==> message"
          # Example: "mongodb 18:18:27.20 INFO ==> ..."
          if .level == null {
            match, err = parse_regex(.message, r'^\w+\s+\d{2}:\d{2}:\d{2}\.\d+\s+(?P<level>[A-Z]+)\s+==>.*')
            if err == null { .level = match.level }
          }
          
          # Pattern 5: Redis log format - looks for timestamp followed by symbol
          # Example: "1:X 22 Nov 2025 03:55:13.181 # +new-epoch 1"
          # Symbols: * = INFO, # = WARNING, - = ERROR, . = DEBUG
          if .level == null {
            match, err = parse_regex(.message, r'\d{2}:\d{2}:\d{2}\.\d+\s+(?P<symbol>[*#.\-])\s+')
            if err == null {
              if match.symbol == "*" { .level = "INFO" }
              if match.symbol == "#" { .level = "WARNING" }
              if match.symbol == "-" { .level = "ERROR" }
              if match.symbol == "." { .level = "DEBUG" }
            }
          }
          
          # Pattern 6: RabbitMQ log format - ISO timestamp with [level] in brackets
          # Example: "2025-11-27 00:50:40.629803+00:00 [error] <0.31222.0> message"
          # Example: "2025-11-27 00:52:11.450115+00:00 [info] <0.31434.0> message"
          if .level == null {
            match, err = parse_regex(.message, r'^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d+\+\d{2}:\d{2}\s+\[(?P<level>(error|info|warning|warn|debug|critical|fatal))\]')
            if err == null {
              # Normalize to uppercase to match other patterns
              level_lower = to_string(match.level)
              if level_lower == "error" { .level = "ERROR" }
              if level_lower == "info" { .level = "INFO" }
              if level_lower == "warning" { .level = "WARNING" }
              if level_lower == "warn" { .level = "WARNING" }
              if level_lower == "debug" { .level = "DEBUG" }
              if level_lower == "critical" { .level = "CRITICAL" }
              if level_lower == "fatal" { .level = "FATAL" }
            }
          }

          # Pattern 7: Go-style key=value logs
          # Example: 'time="2025-11-29T03:19:54Z" level=info msg="..."'
          # Example: 'time=2026-01-01T00:20:28.053Z level=ERROR source=http_error_logger.go:53 msg="..."'
          if .level == null {
            match, err = parse_regex(.message, r'(?i)level=(?P<level>(dbg|debug|inf|info|warn|warning|error|critical|fatal))\b')
            if err == null {
              level_lower = to_string(match.level)
              level_lower = downcase(level_lower)
              if level_lower == "dbg" { .level = "DEBUG" }
              if level_lower == "debug" { .level = "DEBUG" }
              if level_lower == "inf" { .level = "INFO" }
              if level_lower == "info" { .level = "INFO" }
              if level_lower == "warn" { .level = "WARNING" }
              if level_lower == "warning" { .level = "WARNING" }
              if level_lower == "error" { .level = "ERROR" }
              if level_lower == "critical" { .level = "CRITICAL" }
              if level_lower == "fatal" { .level = "FATAL" }
            }
          }
        }
        
        .level = .level || "UNKNOWN"

    # Step 2: Filter by level/namespace/pod (rules applied in order)
    spam_filter:
      type: remap
      inputs: ["unified_parser"]
      source: |
        # Define helper variables
        ns = to_string(.kubernetes.pod_namespace) ?? ""
        level = to_string(.level) ?? "UNKNOWN"
        
        # Parse namespace lists from environment variables
        excluded_ns_str = get_env_var("EXCLUDED_NAMESPACES") ?? ""
        excluded_ns_list = split(excluded_ns_str, ",")
        
        error_filtered_ns_str = get_env_var("ERROR_FILTERED_NAMESPACES") ?? ""
        error_filtered_ns_list = split(error_filtered_ns_str, ",")

        # Rule 0: Exclude specific namespaces entirely (logs are not needed)
        if includes(excluded_ns_list, ns) { abort }

        # Rule 0.5: Filter MongoDB exporter broken pipe and no route to host errors (noisy, non-actionable)
        container = to_string(.kubernetes.container_name) ?? ""
        msg = to_string(.message) ?? ""
        if container == "metrics" && (match(msg, r'(?i)broken pipe') || match(msg, r'(?i)no route to host')) {
          abort
        }

        # Rule 1: System logs → WARNING+ only
        if .source_type == "file" {
          if !match(level, r'(?i)^(WARNING|ERROR|CRITICAL|FATAL)$') { abort }
        } else {
          # Rule 2: Infra namespaces → ERROR+ only
          if includes(error_filtered_ns_list, ns) {
            if !match(level, r'(?i)^(ERROR|CRITICAL|FATAL)$') { abort }
          }
        }

    # Step 3: Standardize fields
    field_slimmer:
      type: remap
      inputs: [spam_filter]
      source: |
        if .source_type == "kubernetes_logs" {
          # 1. Promote key metadata to top-level
          .pod_namespace = .kubernetes.pod_namespace
          .pod_name = .kubernetes.pod_name
          .container_name = .kubernetes.container_name
          .node_name = .kubernetes.pod_node_name
          
          # 2. Remove the heavy nested metadata object
          del(.kubernetes)
        
        } else if .source_type == "file" {
          .node_name = get_env_var("HOSTNAME") ?? "unknown_node"
        }
        
        # 3. Add resource attributes from environment variables
        .project = get_env_var("PROJECT") ?? ""
        .app = get_env_var("APP") ?? ""
        .region = get_env_var("REGION") ?? ""
        .cluster_id = get_env_var("CLUSTER_ID") ?? ""
        .env = get_env_var("ENV") ?? ""
    
    # Step 4: Route logs to different streams based on namespace
    log_router:
      type: route
      inputs: [field_slimmer]
      route:
        kube_system: '.pod_namespace == "kube-system"'
        openobserve: '.pod_namespace == "openobserve"'
        cnpg_system: '.pod_namespace == "cnpg-system"'
        grafana: '.pod_namespace == "grafana"'
        cert_manager: '.pod_namespace == "cert-manager"'
        rabbitmq_system: '.pod_namespace == "rabbitmq-system"'
        tempo: '.pod_namespace == "tempo"'
        victoria-metrics: '.pod_namespace == "victoria-metrics"'
        mongodb: '.pod_namespace == "mongodb"'
        redis: '.pod_namespace == "redis"'
        rabbitmq: '.pod_namespace == "rabbitmq"'
        external-dns: '.pod_namespace == "external-dns"'
        system: '.source_type == "file"'
        other_namespaces: '.source_type == "kubernetes_logs" && !includes(split(get_env_var("ROUTED_NAMESPACES") ?? "", ","), .pod_namespace)'


  # -----------------------------------------------------------------------
  # 3. SINKS
  # Each namespace gets its own stream in OpenObserve
  # -----------------------------------------------------------------------
  sinks:
    # Infra namespaces (ERROR+ only)

    sink_kubernetes_kube-system:
      type: http
      inputs: [log_router.kube_system]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: kube-system
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}
    
    sink_kubernetes_openobserve:
      type: http
      inputs: [log_router.openobserve]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: openobserve
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}
    
    sink_kubernetes_cnpg-system:
      type: http
      inputs: [log_router.cnpg_system]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: cnpg-system
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}
    
    sink_kubernetes_grafana:
      type: http
      inputs: [log_router.grafana]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: grafana
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}
    
    sink_kubernetes_cert-manager:
      type: http
      inputs: [log_router.cert_manager]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: cert-manager
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}
    
    sink_kubernetes_rabbitmq-system:
      type: http
      inputs: [log_router.rabbitmq_system]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: rabbitmq-system
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}

    sink_kubernetes_tempo:  
      type: http
      inputs: [log_router.tempo]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: tempo
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}

    sink_kubernetes_victoria-metrics:
      type: http
      inputs: [log_router.victoria-metrics]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: victoria-metrics
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}

    sink_kubernetes_mongodb:
      type: http
      inputs: [log_router.mongodb]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: mongodb
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}

    sink_kubernetes_redis:
      type: http
      inputs: [log_router.redis]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: redis
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}

    sink_kubernetes_rabbitmq:
      type: http
      inputs: [log_router.rabbitmq]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: rabbitmq
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}

    sink_kubernetes_external-dns:
      type: http
      inputs: [log_router.external-dns]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: external-dns
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}

    # System logs (WARNING+ only)
    sink_system:
      type: http
      inputs: [log_router.system]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: system_logs
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}
    
    # All other namespaces that we might missed
    sink_kubernetes_other:
      type: http
      inputs: [log_router.other_namespaces]
      uri: http://o2-openobserve-router.openobserve.svc.cluster.local:5080
      encoding:
        codec: json
      request:
        headers:
          organization: skies-dota
          stream-name: other_namespaces
          Authorization: Basic ${OPENOBSERVE_AUTH_B64}
